{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generation | met959 | StyleGAN v2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMw3MUCfv0gq2R1BadlR3OO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"k1ot_tfQz1L8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":416},"executionInfo":{"status":"ok","timestamp":1595537501332,"user_tz":420,"elapsed":10575,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzALXjCR6CiGsb4HSk2-XAQKTNozJQ9ssMyVlhQ=s64","userId":"17087927105868275457"}},"outputId":"322a67b5-dc0e-44b0-c0d2-b40261141283"},"source":["%tensorflow_version 1.x # we're using TF v1 as custom for all stylegan endeavors\n","\n","!git clone https://github.com/dvschultz/stylegan2\n","!pip install opensimplex # needed for noise interpolation\n","%cd content/stylegan2 # moves into that folder\n","%mkdir datasets # creates a folder called datasets within the stylegan2 folder"],"execution_count":1,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # we're using TF v1 as custom for all stylegan endeavors`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","Cloning into 'stylegan2'...\n","remote: Enumerating objects: 62, done.\u001b[K\n","remote: Counting objects: 100% (62/62), done.\u001b[K\n","remote: Compressing objects: 100% (56/56), done.\u001b[K\n","remote: Total 544 (delta 9), reused 47 (delta 6), pack-reused 482\u001b[K\n","Receiving objects: 100% (544/544), 22.47 MiB | 26.51 MiB/s, done.\n","Resolving deltas: 100% (274/274), done.\n","Collecting opensimplex\n","  Downloading https://files.pythonhosted.org/packages/60/b4/ca7d6b64166341a951a980628d1cf471947ac00b1eabfbc2008edb4cae32/opensimplex-0.3.tar.gz\n","Building wheels for collected packages: opensimplex\n","  Building wheel for opensimplex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for opensimplex: filename=opensimplex-0.3-cp36-none-any.whl size=14315 sha256=ff12d5026e724a3c1cd2628f607242750f7081e16d67cefd6b6cb92c2ddc47c1\n","  Stored in directory: /root/.cache/pip/wheels/d9/91/27/23b6b8e6237b2b274e128a53a2979644d2978a8968cfbae542\n","Successfully built opensimplex\n","Installing collected packages: opensimplex\n","Successfully installed opensimplex-0.3\n","[Errno 2] No such file or directory: 'content/stylegan2 # moves into that folder'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"paiVuzM93X1l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595537501333,"user_tz":420,"elapsed":824,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzALXjCR6CiGsb4HSk2-XAQKTNozJQ9ssMyVlhQ=s64","userId":"17087927105868275457"}},"outputId":"736f88bb-d49b-4468-b94b-db65e9a90de0"},"source":["%cd /content/stylegan2 "],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/stylegan2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0ONFYVpxRqOu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1595537512494,"user_tz":420,"elapsed":5356,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzALXjCR6CiGsb4HSk2-XAQKTNozJQ9ssMyVlhQ=s64","userId":"17087927105868275457"}},"outputId":"3bbcb0e3-2963-4db6-e93c-7fe6d9dbf91a"},"source":["!gdown --id 1AUVmc1wYSJ01JFvqGa4Bb0OERLdA0fXg"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1AUVmc1wYSJ01JFvqGa4Bb0OERLdA0fXg\n","To: /content/stylegan2/network-snapshot-010625.pkl\n","364MB [00:02, 174MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4g0Yu_F0R1mN","colab_type":"text"},"source":["- since our .pkl file has already been uploaded to Drive, this saves us the download time\n","- downloads to stylegan2 folder, but just move to content folder"]},{"cell_type":"code","metadata":{"id":"-fIWW41x4xW1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1595537611274,"user_tz":420,"elapsed":76777,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzALXjCR6CiGsb4HSk2-XAQKTNozJQ9ssMyVlhQ=s64","userId":"17087927105868275457"}},"outputId":"0802bfef-b882-4b2b-eede-f72785b92a41"},"source":["!python run_generator.py generate-images --network=/content/network-snapshot-010625.pkl --seeds=1-2 --truncation-psi=0.7 "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Local submit - run_dir: results/00000-generate-images\n","dnnlib: Running run_generator.generate_images() on localhost...\n","Loading networks from \"/content/network-snapshot-010625.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n","Generating image for seed 1 (1/2) ...\n","Generating image for seed 2 (2/2) ...\n","dnnlib: Finished run_generator.generate_images() in 1m 08s.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ku_HukNJddE","colab_type":"text"},"source":["- was originally using an outdated snapshot, which yielded problems\n","- 00005-generated-images is the folder with the newly generated images"]},{"cell_type":"code","metadata":{"id":"DsAnG3viJmmH","colab_type":"code","colab":{}},"source":["!zip -r generated-0.7.zip /content/stylegan2/results/00000-generate-images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Q0It0WMKF5G","colab_type":"text"},"source":["- download newly created folder to Desktop"]},{"cell_type":"markdown","metadata":{"id":"MuHVJdyTSnI7","colab_type":"text"},"source":["- now, let's experiment: \n","- take image samples of 5 images\n","- name then to seed#.png and upload to 0000-generate-images folder"]},{"cell_type":"code","metadata":{"id":"2mCuoVOuKj7v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1595539537277,"user_tz":420,"elapsed":3245,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzALXjCR6CiGsb4HSk2-XAQKTNozJQ9ssMyVlhQ=s64","userId":"17087927105868275457"}},"outputId":"566a45ed-b9d8-4617-b2cf-e153eb0b63b3"},"source":["!python run_generator.py generate-latent-walk --network=/content/network-snapshot-010625.pkl --seeds=2,3,8,10,14,23,24,2 --frames 200 --truncation-psi=0.7"],"execution_count":10,"outputs":[{"output_type":"stream","text":["usage: run_generator.py generate-latent-walk [-h] --network NETWORK_PKL\n","                                             [--truncation-psi TRUNCATION_PSI]\n","                                             [--walk-type WALK_TYPE]\n","                                             [--frames FRAMES] [--seeds SEEDS]\n","                                             [--npys NPYS] [--save_vector]\n","                                             [--diameter DIAMETER]\n","                                             [--start_seed START_SEED]\n","                                             [--result-dir DIR]\n","run_generator.py generate-latent-walk: error: argument --seeds: invalid _parse_num_range value: '/content/stylegan2/results/generated-images/frame00001.png,/content/stylegan2/results/generated-images/frame00002.png,/content/stylegan2/results/generated-images/frame00003.png,/content/stylegan2/results/generated-images/frame00004.png,/content/stylegan2/results/generated-images/frame00005.png,/content/stylegan2/results/generated-images/frame00006.png,/content/stylegan2/results/generated-images/frame00001.png'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_IKAebQLOAH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":904},"executionInfo":{"status":"ok","timestamp":1595539254088,"user_tz":420,"elapsed":5442,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzALXjCR6CiGsb4HSk2-XAQKTNozJQ9ssMyVlhQ=s64","userId":"17087927105868275457"}},"outputId":"1d38522e-0d67-4b4a-84c2-0d7e6a455398"},"source":["!ffmpeg -r 24 -i ./results/generated-images/frame%05d.png -vcodec libx264 -pix_fmt yuv420p latent-walk-v2.mp4"],"execution_count":9,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, image2, from './results/generated-images/frame%05d.png':\n","  Duration: 00:00:00.24, start: 0.000000, bitrate: N/A\n","    Stream #0:0: Video: png, rgb24(pc), 1634x780 [SAR 2870:2870 DAR 817:390], 25 fps, 25 tbr, 25 tbn, 25 tbc\n","File 'latent-walk-v2.mp4' already exists. Overwrite ? [y/N] y\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0musing SAR=1/1\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mprofile High, level 3.2\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'latent-walk-v2.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1634x780 [SAR 1:1 DAR 817:390], q=-1--1, 24 fps, 12288 tbn, 24 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame=    6 fps=0.0 q=-1.0 Lsize=     222kB time=00:00:00.12 bitrate=14571.1kbits/s speed=0.151x    \n","video:222kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.401038%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mframe I:2     Avg QP:24.66  size: 41140\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mframe P:2     Avg QP:24.97  size: 40467\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mframe B:2     Avg QP:24.60  size: 31504\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mconsecutive B-frames: 50.0%  0.0% 50.0%  0.0%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mmb I  I16..4: 22.2% 63.0% 14.8%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mmb P  I16..4:  8.4% 28.2% 13.1%  P16..4: 32.9%  3.7%  3.6%  0.0%  0.0%    skip:10.1%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mmb B  I16..4:  2.7%  9.5%  7.0%  B16..8: 27.1%  5.0%  1.2%  direct:15.0%  skip:32.3%  L0:57.0% L1:38.7% BI: 4.3%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0m8x8 transform intra:59.6% inter:55.8%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mcoded y,uvDC,uvAC intra: 70.7% 20.4% 7.1% inter: 36.4% 4.6% 0.2%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mi16 v,h,dc,p: 26% 12% 49% 12%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14%  8% 56%  5%  2%  1%  7%  2%  4%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 12% 23% 10%  4%  2% 14%  3%  6%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mi8c dc,h,v,p: 85%  7%  6%  2%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mWeighted P-Frames: Y:50.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mref P L0: 20.7%  9.7% 30.5% 23.5% 15.7%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mref B L0: 60.6% 39.4%\n","\u001b[1;36m[libx264 @ 0x561d11281e00] \u001b[0mkb/s:7239.10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qIIh-Ms-Lnxh","colab_type":"text"},"source":["- if I wanted to generate way more images, I could have simply used Paperspace as it would be much faster"]}]}